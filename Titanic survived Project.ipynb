{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa849f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Provide the URL of the dataset\n",
    "url = \"https://github.com/dsrscientist/dataset1/raw/master/titanic_train.csv\"\n",
    "\n",
    "# Load the dataset into a Pandas DataFrame\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the DataFrame to inspect the data\n",
    "print(titanic_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of the dataset (number of rows and columns)\n",
    "print(\"Number of rows and columns:\", titanic_df.shape)\n",
    "\n",
    "# Inspect the first few rows to get an overview of the data\n",
    "print(\"\\nFirst few rows of the dataset:\\n\", titanic_df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\\n\", titanic_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns with missing values\n",
    "print(\"Columns with missing values:\\n\", titanic_df.isnull().sum())\n",
    "\n",
    "# Handle missing values in 'Age' by imputing with the mean\n",
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
    "\n",
    "# Handle missing values in 'Embarked' by imputing with the mode\n",
    "titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Drop 'Cabin' column due to a large number of missing values\n",
    "titanic_df.drop(columns=['Cabin'], inplace=True)\n",
    "\n",
    "# Verify that missing values have been handled\n",
    "print(\"\\nColumns with missing values after handling:\\n\", titanic_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf07ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables using one-hot encoding\n",
    "titanic_df = pd.get_dummies(titanic_df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# Display the DataFrame after one-hot encoding\n",
    "print(\"\\nDataFrame after one-hot encoding:\\n\", titanic_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature 'FamilySize'\n",
    "titanic_df['FamilySize'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1\n",
    "\n",
    "# Display the DataFrame after feature engineering\n",
    "print(\"\\nDataFrame after feature engineering:\\n\", titanic_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style for the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Explore the distribution of numerical features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.histplot(titanic_df['Age'], bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Age')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='Pclass', data=titanic_df, palette='viridis')\n",
    "plt.title('Distribution of Passenger Class (Pclass)')\n",
    "plt.show()\n",
    "\n",
    "# Explore the distribution of categorical features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='Sex', data=titanic_df, palette='pastel')\n",
    "plt.title('Distribution of Sex')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='Embarked', data=titanic_df, palette='Set2')\n",
    "plt.title('Distribution of Embarked')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27367800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize relationships between numerical features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='Age', y='Fare', hue='Survived', data=titanic_df, palette='coolwarm')\n",
    "plt.title('Relationship between Age, Fare, and Survival')\n",
    "plt.show()\n",
    "\n",
    "# Visualize relationships between categorical features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.catplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df, kind='bar', palette='muted')\n",
    "plt.title('Survival Rate across Passenger Class and Sex')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d110b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze survival rates across different categories\n",
    "survival_by_class = titanic_df.groupby('Pclass')['Survived'].mean()\n",
    "survival_by_sex = titanic_df.groupby('Sex')['Survived'].mean()\n",
    "survival_by_embarked = titanic_df.groupby('Embarked')['Survived'].mean()\n",
    "\n",
    "print(\"Survival Rate by Passenger Class:\\n\", survival_by_class)\n",
    "print(\"\\nSurvival Rate by Sex:\\n\", survival_by_sex)\n",
    "print(\"\\nSurvival Rate by Embarked:\\n\", survival_by_embarked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between features and target variable\n",
    "correlation_with_survived = titanic_df.corr()['Survived'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Display the correlation coefficients\n",
    "print(\"Correlation with Survived:\\n\", correlation_with_survived)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e03ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming 'X' contains your features and 'y' is the target variable\n",
    "X = titanic_df.drop(columns=['Survived'])\n",
    "y = titanic_df['Survived']\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the data\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importance = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Display feature importances\n",
    "print(\"\\nFeature Importance:\\n\", feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a440f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold for correlation or importance\n",
    "correlation_threshold = 0.1  # Adjust as needed\n",
    "importance_threshold = 0.01  # Adjust as needed\n",
    "\n",
    "# Select features based on the threshold\n",
    "selected_features_corr = correlation_with_survived[correlation_with_survived >= correlation_threshold].index\n",
    "selected_features_importance = feature_importance[feature_importance >= importance_threshold].index\n",
    "\n",
    "# Display selected features\n",
    "print(\"\\nSelected Features based on Correlation:\\n\", selected_features_corr)\n",
    "print(\"\\nSelected Features based on Importance:\\n\", selected_features_importance)\n",
    "\n",
    "# Combine selected features\n",
    "selected_features = set(selected_features_corr).union(selected_features_importance)\n",
    "print(\"\\nFinal Selected Features:\\n\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'selected_features' contains the features you want to use for prediction\n",
    "X = titanic_df[selected_features]\n",
    "y = titanic_df['Survived']\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ddcd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model using the training set\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set for evaluation\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "print(\"Training Set Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "print(\"Testing Set Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f8ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters and their possible values\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform grid search on the training set\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the grid search\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the testing set using the best model\n",
    "y_test_pred_tuned = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned model on the testing set\n",
    "print(\"\\nTuned Model Performance on Testing Set:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_tuned))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred_tuned))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred_tuned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464cece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the hyperparameter distributions\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [None] + list(randint(1, 30, 20)),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(rf_model, param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Perform randomized search on the training set\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the randomized search\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Get the best model from the randomized search\n",
    "best_rf_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the testing set using the best model\n",
    "y_test_pred_tuned = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned model on the testing set\n",
    "print(\"\\nTuned Model Performance on Testing Set:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_tuned))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred_tuned))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred_tuned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'new_data' contains the new observations with the same features used during training\n",
    "# Make sure 'new_data' has the same preprocessing applied as the training data\n",
    "\n",
    "# Use the trained model to make predictions on new data\n",
    "new_data_predictions = best_rf_model.predict(new_data[selected_features])\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Predictions on new data:\\n\", new_data_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances from the best model\n",
    "feature_importance = pd.Series(best_rf_model.feature_importances_, index=selected_features).sort_values(ascending=False)\n",
    "\n",
    "# Display feature importances\n",
    "print(\"Feature Importance:\\n\", feature_importance)\n",
    "\n",
    "# Plot feature importances for better visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importance.plot(kind='barh')\n",
    "plt.title(\"Feature Importance in Predicting Survival\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
