{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d1e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Provide the URL of the dataset\n",
    "url = \"https://github.com/dsrscientist/DSData/raw/master/happiness_score_dataset.csv\"\n",
    "\n",
    "# Load the dataset into a Pandas DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the DataFrame to inspect the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0767f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values by either removing or imputing them\n",
    "# For example, you can impute numerical columns with their mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Check again for missing values to ensure they are handled\n",
    "print(\"\\nMissing values after handling:\\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients between features and the target variable\n",
    "correlation_matrix = df.corr()\n",
    "correlation_with_target = correlation_matrix[\"Happiness Score\"].sort_values(ascending=False)\n",
    "\n",
    "# Display correlation coefficients\n",
    "print(\"Correlation with Happiness Score:\\n\", correlation_with_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6c94af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold for correlation, below which features will be considered irrelevant\n",
    "correlation_threshold = 0.1  # Adjust this threshold as needed\n",
    "\n",
    "# Identify and drop irrelevant columns\n",
    "irrelevant_columns = correlation_with_target[abs(correlation_with_target) < correlation_threshold].index\n",
    "df.drop(columns=irrelevant_columns, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"\\nDataFrame after dropping irrelevant columns:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24433125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of each column to identify categorical variables\n",
    "print(\"Data types:\\n\", df.dtypes)\n",
    "\n",
    "# If there are categorical variables, encode them using one-hot encoding\n",
    "# Example assuming 'Country' is a categorical variable\n",
    "df = pd.get_dummies(df, columns=['Country'], drop_first=True)\n",
    "\n",
    "# Display the DataFrame after encoding\n",
    "print(\"\\nDataFrame after encoding categorical variables:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract numerical columns for scaling\n",
    "numerical_columns = df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the numerical columns\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Display the DataFrame after scaling\n",
    "print(\"\\nDataFrame after scaling numerical variables:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50282eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'Happiness Score' is the target variable\n",
    "X = df.drop(columns=['Happiness Score'])\n",
    "y = df['Happiness Score']\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c1fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"Training Set Performance:\")\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Testing Set Performance:\")\n",
    "print(\"Mean Squared Error:\", mse_test)\n",
    "print(\"R-squared:\", r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters and their possible values\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False],\n",
    "}\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform grid search on the training set\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the grid search\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the testing set using the best model\n",
    "y_test_pred_tuned = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned model on the testing set\n",
    "mse_test_tuned = mean_squared_error(y_test, y_test_pred_tuned)\n",
    "r2_test_tuned = r2_score(y_test, y_test_pred_tuned)\n",
    "\n",
    "print(\"\\nTuned Model Performance on Testing Set:\")\n",
    "print(\"Mean Squared Error:\", mse_test_tuned)\n",
    "print(\"R-squared:\", r2_test_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c41ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a new dataset or new observations in a DataFrame called 'new_data'\n",
    "# Make sure 'new_data' has the same features as the original dataset (excluding the target variable)\n",
    "\n",
    "# Use the best model from hyperparameter tuning to make predictions on new data\n",
    "new_data_predictions = best_model.predict(new_data)\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Predictions on new data:\\n\", new_data_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fad951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature coefficients from the trained model\n",
    "feature_coefficients = pd.Series(best_model.coef_, index=X_train.columns)\n",
    "\n",
    "# Sort the coefficients by magnitude to identify important features\n",
    "sorted_coefficients = feature_coefficients.abs().sort_values(ascending=False)\n",
    "\n",
    "# Display the sorted coefficients\n",
    "print(\"Feature coefficients:\\n\", sorted_coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sorted_coefficients.plot(kind='barh')\n",
    "plt.title(\"Feature Importance in Predicting Happiness Score\")\n",
    "plt.xlabel(\"Coefficient Magnitude\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df52d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between features and target variable\n",
    "correlation_with_target = df.corr()['Happiness Score'].sort_values(ascending=False)\n",
    "\n",
    "# Display the correlation coefficients\n",
    "print(\"Correlation with Happiness Score:\\n\", correlation_with_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbf42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant term to the features matrix (for intercept)\n",
    "X_train_with_const = sm.add_constant(X_train)\n",
    "\n",
    "# Fit a linear regression model with statsmodels to obtain p-values\n",
    "model_stats = sm.OLS(y_train, X_train_with_const).fit()\n",
    "\n",
    "# Display summary statistics, including p-values\n",
    "print(model_stats.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e963581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
